{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:28.313578400Z",
     "start_time": "2024-01-14T13:16:28.305982100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Various torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ------------------------\n",
    "# get up one directory \n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "# ------------------------\n",
    "\n",
    "# custom packages\n",
    "import matplotlib.pyplot as plt\n",
    "import models.aux_funs as maf\n",
    "import optimizers as op\n",
    "import regularizers as reg\n",
    "import train\n",
    "import math\n",
    "import utils.configuration as cf\n",
    "import utils.datasets as ud\n",
    "from models.mnist_conv import mnist_conv\n",
    "from utils.visualise import visualize_layer_weights"
   ],
   "id": "2e3c285c3f738fb4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix the random seed"
   ],
   "id": "c358bd9a28e046d4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:31.663102500Z",
     "start_time": "2024-01-14T13:16:31.635328500Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 2\n",
    "cf.seed_torch(random_seed)"
   ],
   "id": "ad39eccaef5e3443"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the experiment"
   ],
   "id": "c7687c6f50c353d"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:33.719896200Z",
     "start_time": "2024-01-14T13:16:33.703258400Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "l_0s = [0.03, 0.04, 0.05]\n",
    "l_1s = [0.03, 0.04, 0.05]\n",
    "deltas = [1, 0.9, 0.8]\n",
    "\n",
    "combinations = list(itertools.product(l_0s, l_1s, deltas))\n",
    "\n",
    "def print_combination(combination):\n",
    "    print(f'Combination: l_0 = {combination[0]}, l_1 = {combination[1]}, delta = {combination[2]}')\n",
    "\n",
    "base_args = {#\n",
    "    # data specification\n",
    "    'data_file':\"../../Data\",'train_split':0.95, 'data_set':\"Fashion-MNIST\", 'download':True,\n",
    "    # cuda\n",
    "    'use_cuda':False, 'num_workers':0, 'cuda_device':0, 'pin_memory':True,\n",
    "    #\n",
    "    'epochs':100,\n",
    "    # optimizer\n",
    "    'delta':1.0, 'lr':0.07, 'lamda_0':0.4, 'lamda_1':0.4, 'optim':\"AdaBreg\", 'conv_group':True,\n",
    "    'beta':0.0,\n",
    "    # initialization\n",
    "    'sparse_init':0.01, 'r':[1,1,1],\n",
    "    # misc\n",
    "    'random_seed':random_seed, 'eval_acc':True,\n",
    "}\n",
    "\n",
    "args = []\n",
    "for (l_0, l_1, delta) in combinations:\n",
    "    conf_args = base_args.copy()\n",
    "    conf_args['lamda_0'] = l_0\n",
    "    conf_args['lamda_1'] = l_1\n",
    "    conf_args['delta'] = delta\n",
    "    args.append(conf_args)\n",
    "    \n",
    "confs = [cf.Conf(**conf_args) for conf_args in args]\n"
   ],
   "id": "c5a34ced5439ed04"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the models"
   ],
   "id": "edd844407b244080"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:36.173236100Z",
     "start_time": "2024-01-14T13:16:36.092979Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = [{'mean':conf.data_set_mean, 'std':conf.data_set_std} for conf in confs]   \n",
    "\n",
    "models = [mnist_conv(**kwarg) for kwarg in kwargs]\n",
    "\n",
    "best_models = [train.best_model(mnist_conv(**kwarg).to(conf.device)) for kwarg, conf in zip(kwargs, confs)]"
   ],
   "id": "ef832d7bd29d6f53"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight initializations"
   ],
   "id": "169297f3ee61b218"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:38.394894700Z",
     "start_time": "2024-01-14T13:16:38.350168200Z"
    }
   },
   "outputs": [],
   "source": [
    "   \n",
    "def init_weights(conf, model):\n",
    "    # sparsify\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0])\n",
    "    maf.sparse_bias_uniform_(model, 0,conf.r[0],ltype=torch.nn.Conv2d)\n",
    "    maf.sparse_weight_normal_(model, conf.r[1])\n",
    "    maf.sparse_weight_normal_(model, conf.r[2],ltype=torch.nn.Conv2d)\n",
    "    #\n",
    "    maf.sparsify_(model, conf.sparse_init, ltype = nn.Conv2d, conv_group=conf.conv_group)\n",
    "    model = model.to(conf.device)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "initialized_models = [init_weights(conf, model) for conf, model in zip(confs, models)]"
   ],
   "id": "9898fc77085ba57f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ],
   "id": "7a6f49bc576f014e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:40.783119800Z",
     "start_time": "2024-01-14T13:16:40.763282300Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_opt(conf, model):\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Get access to different model parameters\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    weights_conv = maf.get_weights_conv(model)\n",
    "    weights_linear = maf.get_weights_linear(model)\n",
    "    biases = maf.get_bias(model)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # Initialize optimizer\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    if conf.conv_group:\n",
    "        reg2 = reg.reg_l1_l2_conv(lamda=conf.lamda_0)\n",
    "    else:\n",
    "        reg2 = reg.reg_l1(lamda=conf.lamda_0)\n",
    "    \n",
    "    if conf.optim == \"SGD\":\n",
    "        opt = torch.optim.SGD(model.parameters(), lr=conf.lr, momentum=conf.beta)\n",
    "    elif conf.optim == \"LinBreg\":\n",
    "        opt = op.LinBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2, 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])\n",
    "    elif conf.optim == \"ProxSGD\":\n",
    "        opt = op.ProxSGD([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2, 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1), 'momentum':conf.beta,'delta':conf.delta},\n",
    "                          {'params': biases, 'lr': conf.lr, 'momentum':conf.beta}])            \n",
    "    elif conf.optim == \"AdaBreg\":\n",
    "        opt = op.AdaBreg([{'params': weights_conv, 'lr' : conf.lr, 'reg' : reg2,'delta':conf.delta},\n",
    "                           {'params': weights_linear, 'lr' : conf.lr, 'reg' : reg.reg_l1(lamda=conf.lamda_1),'delta':conf.delta},\n",
    "                           {'params': biases, 'lr': conf.lr}])\n",
    "    elif conf.optim == \"L1SGD\":\n",
    "        def weight_reg(model):\n",
    "            reg1 =  reg.reg_l1(lamda=conf.lamda_1)\n",
    "        \n",
    "            loss1 = reg1(model.layers2[0].weight) + reg1(model.layers2[2].weight)\n",
    "            loss2 = reg2(model.layers1[0].weight) + reg2(model.layers1[3].weight)\n",
    "            return loss1 + loss2\n",
    "        \n",
    "        conf.weight_reg = weight_reg\n",
    "        \n",
    "        opt = torch.optim.SGD(model.parameters())\n",
    "    elif conf.optim == \"Adam\":\n",
    "        opt = torch.optim.Adam(model.parameters())\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Optimizer specified\")\n",
    "\n",
    "    # learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=5,threshold=0.01)\n",
    "    \n",
    "    return opt, scheduler"
   ],
   "id": "330cd23b2c066995"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ],
   "id": "438b9da0c473c1cd"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:46.124666400Z",
     "start_time": "2024-01-14T13:16:42.505587300Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader, valid_loader, test_loader = ud.get_data_set(conf)\n",
    "\n",
    "data = [ud.get_data_set(conf) for conf in confs]"
   ],
   "id": "49c8e5ed2ab52b34"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History and Runs"
   ],
   "id": "603950408214dc4d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T13:16:54.814733100Z",
     "start_time": "2024-01-14T13:16:54.806685900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize history\n",
    "tracked = ['loss', 'node_sparse']\n",
    "# train_hist = {}\n",
    "# val_hist = {}\n",
    "\n",
    "train_hists = [{} for conf in confs]\n",
    "val_hists = [{} for conf in confs]"
   ],
   "id": "c9e971bc87099a52"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mconfs\u001B[49m)):\n\u001B[0;32m      2\u001B[0m     combination \u001B[38;5;241m=\u001B[39m combinations[index]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCombination:\u001B[39m\u001B[38;5;124m'\u001B[39m, combination)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'confs' is not defined"
     ]
    }
   ],
   "source": [
    "for index in range(len(confs)):\n",
    "    combination = combinations[index]\n",
    "    print_combination(combination)\n",
    "    conf = confs[index]\n",
    "    model = initialized_models[index]\n",
    "    best_model = best_models[index]\n",
    "    opt, scheduler = init_opt(conf, model)\n",
    "    train_loader, valid_loader, test_loader = data[index]\n",
    "    train_hist = train_hists[index]\n",
    "    val_hist = val_hists[index]\n",
    "\n",
    "    # train the model\n",
    "    for epoch in range(conf.epochs):\n",
    "        print(25*\"<>\")\n",
    "        print(50*\"|\")\n",
    "        print(25*\"<>\")\n",
    "        print('Epoch:', epoch)\n",
    "    \n",
    "        # ------------------------------------------------------------------------\n",
    "        # train step, log the accuracy and loss\n",
    "        # ------------------------------------------------------------------------\n",
    "        train_data = train.train_step(conf, model, opt, train_loader)\n",
    "    \n",
    "        # update history\n",
    "        for key in tracked:\n",
    "            if key in train_data:\n",
    "                var_list = train_hist.setdefault(key, [])\n",
    "                var_list.append(train_data[key])           \n",
    "    \n",
    "        # ------------------------------------------------------------------------\n",
    "        # validation step\n",
    "        val_data = train.validation_step(conf, model, opt, valid_loader)\n",
    "    \n",
    "        # update validation history\n",
    "        for key in tracked:\n",
    "            if key in val_data:\n",
    "                var = val_data[key]\n",
    "                if isinstance(var, list):\n",
    "                    for i, var_loc in enumerate(var):\n",
    "                        key_loc = key+\"_\" + str(i)\n",
    "                        var_list = val_hist.setdefault(key_loc, [])\n",
    "                        val_hist[key_loc].append(var_loc)\n",
    "                else:\n",
    "                    var_list = val_hist.setdefault(key, [])\n",
    "                    var_list.append(var)   \n",
    "    \n",
    "    \n",
    "        scheduler.step(train_data['loss'])\n",
    "        print(\"Learning rate:\",opt.param_groups[0]['lr'])\n",
    "        best_model(train_data['acc'], val_data['acc'], model=model)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T12:43:37.197808400Z",
     "start_time": "2024-01-16T12:43:36.861178800Z"
    }
   },
   "id": "bf4b5d4460e8103f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ],
   "id": "15a7846fe5785b87"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:23:31.765463Z",
     "start_time": "2024-01-02T17:16:38.153773Z"
    }
   },
   "outputs": [],
   "source": [
    "# # -----------------------------------------------------------------------------------\n",
    "# # Reinit weigts and the corresponding optimizer\n",
    "# # -----------------------------------------------------------------------------------\n",
    "# model = init_weights(conf, model)\n",
    "# opt, scheduler = init_opt(conf, model)\n",
    "# \n",
    "# # -----------------------------------------------------------------------------------\n",
    "# # train the model\n",
    "# # -----------------------------------------------------------------------------------\n",
    "# for epoch in range(conf.epochs):\n",
    "#     print(25*\"<>\")\n",
    "#     print(50*\"|\")\n",
    "#     print(25*\"<>\")\n",
    "#     print('Epoch:', epoch)\n",
    "# \n",
    "#     # ------------------------------------------------------------------------\n",
    "#     # train step, log the accuracy and loss\n",
    "#     # ------------------------------------------------------------------------\n",
    "#     train_data = train.train_step(conf, model, opt, train_loader)\n",
    "# \n",
    "#     # update history\n",
    "#     for key in tracked:\n",
    "#         if key in train_data:\n",
    "#             var_list = train_hist.setdefault(key, [])\n",
    "#             var_list.append(train_data[key])           \n",
    "# \n",
    "#     # ------------------------------------------------------------------------\n",
    "#     # validation step\n",
    "#     val_data = train.validation_step(conf, model, opt, valid_loader)\n",
    "# \n",
    "#     # update validation history\n",
    "#     for key in tracked:\n",
    "#         if key in val_data:\n",
    "#             var = val_data[key]\n",
    "#             if isinstance(var, list):\n",
    "#                 for i, var_loc in enumerate(var):\n",
    "#                     key_loc = key+\"_\" + str(i)\n",
    "#                     var_list = val_hist.setdefault(key_loc, [])\n",
    "#                     val_hist[key_loc].append(var_loc)\n",
    "#             else:\n",
    "#                 var_list = val_hist.setdefault(key, [])\n",
    "#                 var_list.append(var)   \n",
    "# \n",
    "# \n",
    "#     scheduler.step(train_data['loss'])\n",
    "#     print(\"Learning rate:\",opt.param_groups[0]['lr'])\n",
    "#     best_model(train_data['acc'], val_data['acc'], model=model)"
   ],
   "id": "29bb1b3ad027c135"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.01\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9081\n",
      "--------------------------------------------------\n",
      "Sparsity: 0.05\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9114\n",
      "--------------------------------------------------\n",
      "Sparsity: 0.1\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9115\n",
      "--------------------------------------------------\n",
      "Sparsity: 0.2\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9144\n",
      "--------------------------------------------------\n",
      "Sparsity: 0.5\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9116\n",
      "--------------------------------------------------\n",
      "Sparsity: 1\n",
      "Evaluate\n",
      "Test\n",
      "--------------------------------------------------\n",
      "Test Accuracy: 0.9172\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "for index, combi in enumerate(combinations):\n",
    "    print_combination(combi)\n",
    "    best_model = best_models[index]\n",
    "    conf = confs[index]\n",
    "    test_loader = data[index][2]\n",
    "    \n",
    "    model = best_model.best_model\n",
    "    \n",
    "    torch.save(model.state_dict(), f'../checkpoints/hyperparameters/mnist_conv_{combi[0]}_{combi[1]}_{combi[2]}.pth')\n",
    "    \n",
    "    print('Evaluate')\n",
    "    model.eval()\n",
    "    print('Test')\n",
    "    train.test(conf, model, test_loader)\n",
    "    print('-'*50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:29:36.930471Z",
     "start_time": "2024-01-02T17:29:36.923599Z"
    }
   },
   "id": "4bcb380f2048be82",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:24:06.868326Z",
     "start_time": "2024-01-02T17:24:06.863538Z"
    }
   },
   "id": "fb4a35cca61cd663",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T17:27:20.064114Z",
     "start_time": "2024-01-02T17:27:18.465221Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "id": "bfcff905e94be802",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "870951d83e17fa6f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
